\chapter{Problem Formulation} 

\textbf{FIXME}: Given an observation sequence, typically a phrase, and the model parameters, we are interested 
in detecting and correcting errors, estimating the optimal state sequence. 

In our HMM, the hidden states represent the intended words and the observations are the typed words. 

The initial state probabilities $\pi$ are given by the word frequencies and the state transitions $A_{ij}$, that is 
the probability of one word given its predecessor obtained from ??\textbf{FIXME}

The emission probabilities, $B_{ij}$, represent the probability of a typed word given the intended one, and 
depend on the confusion probabilities.

\textbf{FIXME}: We also detect the non-word error?

\section{Design Choices}

We have chosen the English language for various reasons. First of all, great majority of material in literature 
deals with this problem in the English language. \textcolor{red}{Moreover it is a simple language, both from a 
grammatical and a lexical point of view: it lacks in certain symbols, like accents and apostrophes, and genres. }
Furthermore all punctuation and special character symbols were not considered, but only letters and sometimes 
numbers. 
\\
\textbf{FIXME}:{why??}
We considered that a typed word only depends on the previous one, being in the framework of Markov chains. If 
we know the probability of a word given its predecessor, the frequency of each word, and the probability to type 
word x when word y is intended, we have all the necessary ingredients to use Hidden Markov Models.

\section{Software}
\textbf{FIXME}
We have developed the project in \textbf{Python}.\\
The interface is a native macOS application written in \textbf{Swift}.