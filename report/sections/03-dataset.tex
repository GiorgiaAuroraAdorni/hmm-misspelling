\chapter{Dataset}

\section{Sentences Dataset}
\label{section:sentences_ds}
We used two different datasets of English sentences to construct the transition probability matrix, following the 
procedure described in Section \ref{section:hmm}.\\
The first one is a concatenation of public domain book excerpts from Project 
Gutenberg\footnote{\url{http://www.gutenberg.org/wiki/Main\_Page}}, containing about a million words. 

The second one has been extracted from the collection  of the “Lord Of The Rings” 
books\footnote{\url{https://www.kaggle.com/mokosan/lord-of-the-rings-character-data}}.

We then applied some preprocessing procedures to each corpus, in particular we divided them in lower-case 
sentences and removed special characters and punctuation, obtaining the \texttt{big\_clean} and 
\texttt{lotr\_clean} datasets.


\section{Typos Dataset}
The basic typos dataset was collected from the following resources:
%\footnote{\url{https://www.dcs.bbk.ac.uk/~ROGER/corpora.html}}  
%\footnote{\url{https://www.kaggle.com/rtatman/spelling-variation-on-urban-dictionary}}  
%\footnote{\url{https://www.kaggle.com/bittlingmayer/spelling}}
%\footnote{\url{http://luululu.com/tweet}}
\begin{itemize}
	\item \textsc{birkbeck}\footlabel{note1}{\url{https://www.dcs.bbk.ac.uk/~ROGER/corpora.html}} : contains 
	\num{36133} misspellings of \num{6136} words, taken from the native-speaker section (British and 
	American) of the Birkbeck spelling error corpus.
	\item \textsc{holbrook}\footref{note1}: contains \num{1791} misspellings of \num{1200} words, taken from 
	the book "English for the Rejected" by David Holbrook (Cambridge University Press - 1964).
	\item \textsc{aspell}\footref{note1}: contains \num{531} misspellings of \num{450} words, taken from one 
	assembled by Atkinson for testing the GNU Aspell spellchecker.
	\item \textsc{wikipedia}\footref{note1}: contains \num{2455} misspellings of \num{1922} words, taken from 
	the misspellings made by Wikipedia editors.
	\item \textsc{urban-dictionary-variants} 
	\footnote{\url{https://www.kaggle.com/rtatman/spelling-variation-on-urban-dictionary}}: contains 
	\num{716} variant 
	spellings, taken from the text scraped from Urban Dictionary (in UK English).
	\item \textsc{spell-set}\footnote{\url{https://www.kaggle.com/bittlingmayer/spelling}}: contains 
	\num{670} typos.
	\item \textsc{tweet-typo}\footnote{\url{http://luululu.com/tweet}}: contains \num{39172} typos, taken 
	from Twitter.
\end{itemize}

All the datasets were cleaned and joined in a single one containing \num{79677} rows, each with a typo and the 
corresponding correct word.
This dataset was then divided into two corpora: \num{80}\% is used as a train set (\num{63679} rows) and 
\num{20}\% is used as a test set (\num{15998} rows).

To evaluate the performance of our model, we also created another dataset of typos starting from the \texttt{lotr\_clean} 
file. For each word contained in this corpus we generated five typos according to the algorithm 
that will be defined in Section~\ref{section:perturbed}. This dataset contains \num{62759} rows, with the same 
structure described above. We then split it in train and test datasets, respectively containing \num{50058} and 
\num{12701} rows.

\section{Language Dataset}
A language model represents the frequency of words in a certain language.
We used two different language model datasets. \\
The first one is a lists of most frequent words from 
\href{https://en.wiktionary.org/wiki/Wiktionary:Frequency_lists}{\textcolor{blue}{Wiktionary}} and the 
	\href{http://www.kilgarriff.co.uk/bnc-readme.html}{\textcolor{blue}{British National Corpus}}. 
We use \texttt{frequency-alpha-gcide}, a smaller version derived from the original dataset 
\href{https://books.google.com/ngrams/}{\textcolor{blue}{Google's ngram corpora}}, that includes wordlists, 
cleaned up and limited to only the top \num{65537} words.

We found some problems with this dataset, for example the lack of proper names, city names, countries, brands, 
etc. Moreover, most of the typical words of the language used in the sentence dataset were missing.
For this reason, we decided to create a new language model \texttt{lotr\_language\_model}, based on the 
frequency of the \num{12506} distinct words in the \texttt{lotr\_clean} dataset.

Both of these datasets contain, for each word, the frequency it appears in the corresponding text corpus.

\section{Perturbed Dataset}
\label{section:perturbed}
In order to evaluate the performance of our algorithm on the Most Likely Sequence task, we created new datasets of 
perturbed sentences, starting from the \texttt{big\_clean} and \texttt{lotr\_clean} datasets described in 
Section~\ref{section:sentences_ds}.

Estimates for the frequency of spelling errors in human-typed text vary greatly depending on the situation: from 1-2\% 
when carefully retyping already printed text to 10-15\% when writing web queries. For this reason, we generated three 
different texts from each dataset, with varying the percentage of errors introduced, as described below.

Our perturbation algorithm generates a new perturbed string for each line of the input texts, according to the 
following steps. We obtain the probabilities of introducing each class of errors using the error model described in  
Section~\ref{section:ncm}.

\begin{enumerate}
	\item The probability that a word has an edit is computed by multiplying the value of $p$ (the probability that a 
	certain letter has an edit), contained in the error model, by \num{5}-\num{10}-\num{15}\% that ideally 
	represents the percentage of errors desired.
	\item For each word of length $n$, the number of edits to be introduced $x$ is calculated according to the 
	probability distribution $x \sim \text{Bin}(n, p)$. We make the assumption that the number of errors in a word 
	follows a binomial distribution depending on the single-character error probability and the length of the word. 
	\item The $x$ characters to be changed inside each word are chosen randomly.
	\item The type of edit to be applied to each character is chosen randomly according to the probabilities contained 
	in the error model. We use four different probabilities to define whether a letter will be deleted, a new letter 
	will be inserted, the current character will be replaced with another or the current character will be swapped with 
	the next or the previous one.
	
\end{enumerate}

Swap errors are only introduced if there are no further changes in the word. Furthermore, cases of elimination of a 
whole word are excluded, as these would not be detectable with our model.


%(\num{58000} sentence)

%\begin{lstlisting}[
%label={code:perturbation-algorithm},
%caption={Text perturbation algorithm},
%captionpos=b,
%breaklines=true,                                    
%language=Python,
%frame=ltrb,
%framesep=5pt,
%basicstyle=\small,
%keywordstyle=\ttfamily\color{OliveGreen},
%identifierstyle=\ttfamily\color{MidnightBlue}\bfseries,
%commentstyle=\color{Brown},
%stringstyle=\ttfamily,
%showstringspaces=false
%]
%def perturb():
%	# Create a model for the test set
%	hmm = HMM(1, max_edits=2, max_states=3)
%	hmm.train(words_ds="../data/word_freq/frequency-alpha-gcide.txt",
%					   sentences_ds="../data/texts/big_clean.txt",
%					   typo_ds="../data/typo/clean/test.csv")
%	
%	cleaned = open("../data/texts/big_clean.txt", "r")
%	
%	if not os.path.exists("../data/texts//"):
%		os.makedirs("../data/texts/perturbated/")
%	
%	perturbed = open("../data/texts/perturbated/big_perturbed.txt", "w")
%	
%	# probability that a word has an edit
%	p = hmm.error_model["p"]
%	
%	# probability of the various edit
%	prob_swap = hmm.error_model["swap"]
%	prob_ins = hmm.error_model["ins"]
%	prob_del = hmm.error_model["del"]
%	prob_sub = 1 - (prob_swap + prob_ins + prob_del)
%	
%	edit_prob = [prob_swap, prob_ins, prob_del, prob_sub]
%	
%	for i, e in enumerate(edit_prob):
%		if i == 0:
%			continue
%	
%	edit_prob[i] = edit_prob[i] + edit_prob[i - 1]
%	
%	def substitute(word):
%		l = list(word)
%		if not l[indices[j]] in hmm.error_model["sub"]:
%			l[indices[j]] = random.choice(string.ascii_letters).lower()
%		else:
%			l[indices[j]] = np.random.choice(list(hmm.error_model["sub"][l[indices[j]]].keys()))
%		return "".join(l)
%	
%	for line in cleaned:
%		line_words = line.split()
%	
%		for i, word in enumerate(line_words):
%			n = len(word)
%			# number of errors to introduce in the word
%			x = np.random.binomial(n, p)        # x ~ Bin(p, n)
%
%			# choose two letter to change
%			indices = np.random.choice(n, x, replace=False)
%			indices = -np.sort(-indices)
%			
%			for j in range(x):
%				r = np.random.random()
%				
%				for k, e in enumerate(edit_prob):
%					if r <= edit_prob[k]:
%						break
%					value = k
%
%				# swap if you have to do only one edit
%				if value == 0 and x == 1:
%					# if the letter to switch is the last one, switch with the previous one
%					if len(indices) <= j + 1:
%						word = word[0:indices[j] - 1] + word[indices[j]] + word[indices[j] - 1] +  word[indices[j] + 1:]
%					else:
%						word = word[0:indices[j]] + word[indices[j] + 1] + word[indices[j]] + word[indices[j] + 2:]
%
%				# insert a letter in a random position (after idx)
%				elif value == 1:
%					new_letter = random.choice(string.ascii_letters)
%					word = word[0:indices[j]] + new_letter + word[indices[j] + 1:]
%				
%				# delete a letter
%				elif value == 2:
%					if len(word) == 1:
%						# if the word is 1 char, don't delete the word but substitute it with another one
%						word = substitute(word)
%					else:
%						word = word[0:indices[j]] + word[indices[j] + 1:]
%
%				# substitute a letter
%				else:
%					word = substitute(word)
%
%			line_words[i] = word
%
%		line = " ".join(line_words)
%		perturbed.write(line + '\n')
%				
%	perturbed.close()
%	cleaned.close()
%\end{lstlisting}


